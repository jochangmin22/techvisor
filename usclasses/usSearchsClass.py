from utils import remove_tail
from django.core.cache import cache

from ipclasses import IpSearchs

class UsSearchs(IpSearchs):

    def redis_nlp(self):
        try:
            result = cache.get(f'{self._subKey}_nlp_rows')            
            if result:
                print(f'load {self.__class__.__name__} subKey_nlp_rows redis', self._mode)
                self._nlp_rows = result
        except (KeyError, NameError, UnboundLocalError):
            pass                               

    def wordcloud(self):
        self.load_rows_first()

        self.redis_nlp()

        try:
            getattr(self, '_nlp_rows')
            print('_nlp_rows exist')
        except AttributeError:
            print('nlp_rows execute')
            return self.nlp_rows()           
        else:
            return self._nlp_rows   

    def keywords(self):
        self.load_rows_first()

        self.redis_nlp()

        try:
            getattr(self, '_nlp_rows')
            print('_nlp_rows exist')
        except AttributeError:
            print('nlp_rows execute')
            return self.nlp_rows()           
        else:
            return self._nlp_rows  

    def nlp_rows(self):
        result = self.make_nlp_rows(self.create_empty_rows())
        return self.save_redis_sub_nlp_rows(result)

    def make_mtx_rows(self, result):
        # matrixλ” μ¶μ›λ²νΈ, μ¶μ›μΌ, μ¶μ›μΈ1, ipcμ½”λ“, μ”μ•½, μ²­κµ¬ν•­λ§ μ‚¬μ©
        for i in range(len(result)):
            for key in ['μ¶μ›λ²νΈ','μ¶μ›μΈ1','ipcμ½”λ“']:
                result[i][key] = self._rows[i][key]            

            result[i]['μ¶μ›μΌ'] =  str(self._rows[i]['μ¶μ›μΌ'])[:-4]
            result[i]['μ¶μ›μΈμ£Όμ²΄'] = True

            abstract = str(self._rows[i]['μ”μ•½'])
            claim = str(self._rows[i]['μ²­κµ¬ν•­'])
            result[i]['μ”μ•½'] = abstract
            result[i]['μ²­κµ¬ν•­'] = claim
            result[i]['μ”μ•½Β·μ²­κµ¬ν•­'] = abstract + ' ' + claim      
        return result

    def save_redis_sub_nlp_rows(self, result):
        cache.set(f'{self._subKey}_nlp_rows', result)
        return result

    def generate_num_query(self):
        query = 'select count(*) over () as cnt, ' + self._queryCols + \
        " FROM us_view WHERE num_search like '%" + self._searchNum.replace("-","") + "%'"
        return query

    def generate_text_query(self):
        queryTextTerms = self.tsquery_keywords(self._searchText, 'terms')
        whereTerms = f'"{self._searchVolume}tsv" @@ to_tsquery(\'{queryTextTerms}\') and ' if queryTextTerms else ""

        queryTextInventor = self.tsquery_keywords(self._inventor, 'person')
        whereInventor = f'"λ°λ…μtsv" @@ to_tsquery(\'{queryTextInventor}\') and ' if queryTextInventor else ""

        queryTextAssignee = self.tsquery_keywords(self._assignee, 'person')
        whereAssignee = f'"μ¶μ›μΈtsv" @@ to_tsquery(\'{queryTextAssignee}\') and ' if queryTextAssignee else ""

        whereDate = self.date_query()
        whereStatus = self.status_query()
        whereIptype = self.iptype_query()

        whereAll = whereTerms
        whereAll += whereDate
        whereAll += whereInventor
        whereAll += whereAssignee
        whereAll += whereStatus
        whereAll += whereIptype

        whereAll = remove_tail(whereAll," and ")

        query = f'select count(*) over () as cnt, US.* FROM ({self.searchs_query(queryTextTerms)}) AS US order by μ¶μ›μΌ DESC'
        print('π’™ us query :', query)
        return query

    def searchs_query(self, queryTextTerms):
        ''' νΉν—λ¬Έν—μ½”λ“ B only ; 'Live' '''
        return f"""
        SELECT
        A.μ¶μ›λ²νΈ,
        'Live' AS λ“±λ΅μ‚¬ν•­,
        A.λ¬Έν—λ²νΈ,
        A.μ¶μ›μΌ,
        A.λ“±λ΅μΌ,
        A.κ³µκ°μΌ,
        A.λ°λ…μλ…μΉ­,
        K.μ°λ²1 AS μ°μ„ κ¶μ£Όμ¥μ¶μ›μΌ1,
        trim(regexp_replace(regexp_replace(regexp_replace(regexp_replace(B.μ”μ•½, '<[^>]+>', '', 'g'), '[\(\[].*?[\)\]]','', 'g'), '[^[:alnum:],/.;:]',' ','g'),'\s+',' ','g')) AS μ”μ•½,
        trim(regexp_replace(regexp_replace(regexp_replace(regexp_replace(C.μ²­κµ¬ν•­, '<[^>]+>', '', 'g'), '[\(\[].*?[\)\]]','', 'g'), '[^[:alnum:],/.;:]',' ','g'),'\s+',' ','g')) AS μ²­κµ¬ν•­,
        D."μ¶μ›μΈ1", D."μ¶μ›μΈκµ­κ°€μ½”λ“1", '1' AS "μ¶μ›μΈμ½”λ“1",
        F."λ°λ…μ1", F."λ°λ…μκµ­κ°€μ½”λ“1", 
        H.ipcμ½”λ“,
        concat_ws(' ', A.λ¬Έν—λ²νΈ, A.κ³µλ³΄λ²νΈ,  A.λ“±λ΅λ²νΈ, A.κ³µκ°λ²νΈ, A.μ¶μ›λ²νΈ,  A.κµ­μ κ³µκ°λ²νΈ, K.μ°λ²1, L.μ°λ²2) AS NUM_SEARCH
        FROM
           ( select λ¬Έν—λ²νΈ from us_view WHERE "search" @@ to_tsquery(\'{queryTextTerms}\') and λ¬Έν—λ²νΈ like '____________B_' GROUP BY λ¬Έν—λ²νΈ) Z 
            LEFT JOIN "US_BIBLIO" A  ON Z.λ¬Έν—λ²νΈ = A.λ¬Έν—λ²νΈ
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, μ”μ•½ FROM "US_ABSTRACT") B ON Z.λ¬Έν—λ²νΈ = B.λ¬Έν—λ²νΈ 
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, μ²­κµ¬ν•­ FROM "US_CLAIM") C ON Z.λ¬Έν—λ²νΈ = C.λ¬Έν—λ²νΈ
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, μ΄λ¦„ AS "μ¶μ›μΈ1", κµ­μ  AS "μ¶μ›μΈκµ­κ°€μ½”λ“1" FROM "US_REL_PSN" WHERE "κµ¬λ¶„" = 'μ¶μ›μΈ' AND "μΌλ ¨λ²νΈ" = 1 ) D ON Z.λ¬Έν—λ²νΈ = D.λ¬Έν—λ²νΈ
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, μ΄λ¦„ AS "λ°λ…μ1", κµ­μ  AS "λ°λ…μκµ­κ°€μ½”λ“1" FROM "US_REL_PSN" WHERE "κµ¬λ¶„" = 'λ°λ…μ' AND "μΌλ ¨λ²νΈ" = 1 ) F ON Z.λ¬Έν—λ²νΈ = F.λ¬Έν—λ²νΈ
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, ipcμ½”λ“ FROM "US_IPC" WHERE μΌλ ¨λ²νΈ = 1 ) H ON Z.λ¬Έν—λ²νΈ = H.λ¬Έν—λ²νΈ 
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, μ°μ„ κ¶μ£Όμ¥μ¶μ›λ²νΈ AS "μ°λ²1" FROM "US_PRIR" WHERE "μΌλ ¨λ²νΈ" = 1 ) K ON Z.λ¬Έν—λ²νΈ = K.λ¬Έν—λ²νΈ
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, μ°μ„ κ¶μ£Όμ¥μ¶μ›λ²νΈ AS "μ°λ²2" FROM "US_PRIR" WHERE "μΌλ ¨λ²νΈ" = 2 ) L ON Z.λ¬Έν—λ²νΈ = L.λ¬Έν—λ²νΈ                  
        """

from utils import remove_tail, sampling
from django.core.cache import cache
from django.conf import settings
NAVER = settings.NAVER
import requests

from ipclasses import IpSearchs

class UsSearchs(IpSearchs):

    def redis_nlp(self):
        try:
            result = cache.get(f'{self._subKey}_nlp_rows')            
            if result:
                print(f'load {self.__class__.__name__} subKey_nlp_rows redis', self._mode)
                self._nlp_rows = result
        except (KeyError, NameError, UnboundLocalError):
            pass                               

    def wordcloud(self):
        self.load_rows_first()

        self.redis_nlp()

        try:
            getattr(self, '_nlp_rows')
            print('_nlp_rows exist')
        except AttributeError:
            print('nlp_rows execute')
            return self.nlp_rows()           
        else:
            return self._nlp_rows   

    def keywords(self):
        self.load_rows_first()

        self.redis_nlp()

        try:
            getattr(self, '_nlp_rows')
            print('_nlp_rows exist')
        except AttributeError:
            print('nlp_rows execute')
            return self.nlp_rows()           
        else:
            return self._nlp_rows  

    def nlp_rows(self):
        result = self.make_nlp_rows(self.create_empty_rows())
        return self.save_redis_sub_nlp_rows(result)

    def make_mtx_rows(self, result):
        # matrixλ” μ¶μ›λ²νΈ, μ¶μ›μΌ, μ¶μ›μΈ1, ipcμ½”λ“, μ”μ•½, μ²­κµ¬ν•­λ§ μ‚¬μ©
        for i in range(len(result)):
            for key in ['μ¶μ›λ²νΈ','μ¶μ›μΈ1','ipcμ½”λ“']:
                result[i][key] = self._rows[i][key]            

            result[i]['μ¶μ›μΌ'] =  str(self._rows[i]['μ¶μ›μΌ'])[:-4]
            result[i]['μ¶μ›μΈμ£Όμ²΄'] = True

            abstract = str(self._rows[i]['μ”μ•½'])
            claim = str(self._rows[i]['μ²­κµ¬ν•­'])
            result[i]['μ”μ•½'] = abstract
            result[i]['μ²­κµ¬ν•­'] = claim
            result[i]['μ”μ•½Β·μ²­κµ¬ν•­'] = abstract + ' ' + claim      
        return result

    def save_redis_sub_nlp_rows(self, result):
        cache.set(f'{self._subKey}_nlp_rows', result)
        return result

    def generate_num_query(self):
        query = 'select count(*) over () as cnt, ' + self._queryCols + \
        " FROM us_view WHERE num_search like '%" + self._searchNum.replace("-","") + "%'"
        return query

    def generate_text_query(self):
        queryTextTerms = self.tsquery_keywords(self._searchText, 'terms')
        whereTerms = f'"{self._searchVolume}tsv" @@ to_tsquery(\'{queryTextTerms}\') and ' if queryTextTerms else ""

        queryTextInventor = self.tsquery_keywords(self._inventor, 'person')
        whereInventor = f'"λ°λ…μtsv" @@ to_tsquery(\'{queryTextInventor}\') and ' if queryTextInventor else ""

        queryTextAssignee = self.tsquery_keywords(self._assignee, 'person')
        whereAssignee = f'"μ¶μ›μΈtsv" @@ to_tsquery(\'{queryTextAssignee}\') and ' if queryTextAssignee else ""

        whereDate = self.date_query()
        whereStatus = self.status_query()
        whereIptype = self.iptype_query()

        whereAll = whereTerms
        whereAll += whereDate
        whereAll += whereInventor
        whereAll += whereAssignee
        whereAll += whereStatus
        whereAll += whereIptype

        whereAll = remove_tail(whereAll," and ")

        query = f'select count(*) over () as cnt, US.* FROM ({self.searchs_query(queryTextTerms)}) AS US order by μ¶μ›μΌ DESC'
        print('π’™ us query :', query)
        return query

    def make_paging_rows(self, result):
        try:
            rowsCount = self._rows[0]["cnt"]
        except (KeyError, IndexError):        
            rowsCount = 0

        for i in range(len(result)):
            result[i]['id'] = self._rows[i]['μ¶μ›λ²νΈ'] # add id key for FE's ids
            for key in ['λ¬Έν—λ²νΈ','λ¬Έν—λ²νΈenrich', 'λ¬Έν—μΌ','μ¶μ›λ²νΈ','μ¶μ›μΌ','μ΅΄μ†κΈ°κ°„λ§λ£μΌ','λ“±λ΅μ‚¬ν•­','λ°λ…μλ…μΉ­','μ¶μ›μΈ1','ipcμ½”λ“']:
                result[i][key] = self._rows[i][key]

        rows = sampling(result, self._offset, self._limit)

        # foo = '.Β¶'.join(d['λ°λ…μλ…μΉ­'] for d in rows)
        # bar = self.list_to_string_with_delimiter(foo)
        # rows.update('λ°λ…μλ…μΉ­', bar.split('.Β¶'))

        return { 'rowsCount': rowsCount, 'rows': rows}    

    def list_to_string_with_delimiter(self, myList):
        result = ''
        for i in range(len(myList)):
            result += f'''{myList[i]}.Β¶'''
        return result

    def get_translate(text):
        client_id = NAVER['papago_client_id']
        client_secret = NAVER['papago_client_secret']

        data = {'text' : text,
                'source' : 'en',
                'target': 'ko'}
                
        url = NAVER['papago_url']

        header = {"X-Naver-Client-Id":client_id,
                "X-Naver-Client-Secret":client_secret}

        response = requests.post(url, headers=header, data=data)
        rescode = response.status_code

        if(rescode==200):
            send_data = response.json()
            trans_data = (send_data['message']['result']['translatedText'])
            return trans_data
        else:
            print("Error Code:" , rescode)        

    def searchs_query(self, queryTextTerms):
        ''' νΉν—λ¬Έν—μ½”λ“ B only ; 'Live' '''
        return f"""
        SELECT
        A.μ¶μ›λ²νΈ,
        'Live' AS λ“±λ΅μ‚¬ν•­,
        A.λ¬Έν—λ²νΈ,
        CONCAT('US ', TRIM (
		LEADING '0'
		FROM
			CAST (concat_ws(' ',
                 left(A.λ¬Έν—λ²νΈ, 12),
                 right(A.λ¬Έν—λ²νΈ,2)
                ) AS TEXT)
	    )) λ¬Έν—λ²νΈenrich,
        CASE
            WHEN A.λ“±λ΅μΌ IS NULL
            THEN A.κ³µκ°μΌ
            ELSE A.λ“±λ΅μΌ
        END λ¬Έν—μΌ,
        CASE
            WHEN A.λ“±λ΅μΌ IS NULL
            THEN NULL
            ELSE to_char(A.μ¶μ›μΌ::text::date + INTERVAL '20 year', 'yyyymmdd')
        END μ΅΄μ†κΈ°κ°„λ§λ£μΌ,
        A.μ¶μ›μΌ,
        A.λ“±λ΅μΌ,
        A.κ³µκ°μΌ,
        A.λ°λ…μλ…μΉ­,
        K.μ°λ²1 AS μ°μ„ κ¶μ£Όμ¥μ¶μ›μΌ1,
        trim(regexp_replace(regexp_replace(regexp_replace(regexp_replace(B.μ”μ•½, '<[^>]+>', '', 'g'), '[\(\[].*?[\)\]]','', 'g'), '[^[:alnum:],/.;:]',' ','g'),'\s+',' ','g')) AS μ”μ•½,
        trim(regexp_replace(regexp_replace(regexp_replace(regexp_replace(C.μ²­κµ¬ν•­, '<[^>]+>', '', 'g'), '[\(\[].*?[\)\]]','', 'g'), '[^[:alnum:],/.;:]',' ','g'),'\s+',' ','g')) AS μ²­κµ¬ν•­,
        D."μ¶μ›μΈ1", D."μ¶μ›μΈκµ­κ°€μ½”λ“1", '1' AS "μ¶μ›μΈμ½”λ“1",
        F."λ°λ…μ1", F."λ°λ…μκµ­κ°€μ½”λ“1", 
        H."ipcμ½”λ“",
        concat_ws(' ', A.λ¬Έν—λ²νΈ, A.κ³µλ³΄λ²νΈ,  A.λ“±λ΅λ²νΈ, A.κ³µκ°λ²νΈ, A.μ¶μ›λ²νΈ,  A.κµ­μ κ³µκ°λ²νΈ, K.μ°λ²1, L.μ°λ²2) AS NUM_SEARCH
        FROM
           ( select λ¬Έν—λ²νΈ from us_view WHERE "search" @@ to_tsquery(\'{queryTextTerms}\') and λ¬Έν—λ²νΈ like '____________B_' GROUP BY λ¬Έν—λ²νΈ) Z 
            LEFT JOIN "US_BIBLIO" A  ON Z.λ¬Έν—λ²νΈ = A.λ¬Έν—λ²νΈ
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, μ”μ•½ FROM "US_ABSTRACT") B ON Z.λ¬Έν—λ²νΈ = B.λ¬Έν—λ²νΈ 
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, μ²­κµ¬ν•­ FROM "US_CLAIM") C ON Z.λ¬Έν—λ²νΈ = C.λ¬Έν—λ²νΈ
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, μ΄λ¦„ AS "μ¶μ›μΈ1", κµ­μ  AS "μ¶μ›μΈκµ­κ°€μ½”λ“1" FROM "US_REL_PSN" WHERE "κµ¬λ¶„" = 'μ¶μ›μΈ' AND "μΌλ ¨λ²νΈ" = 1 ) D ON Z.λ¬Έν—λ²νΈ = D.λ¬Έν—λ²νΈ
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, μ΄λ¦„ AS "λ°λ…μ1", κµ­μ  AS "λ°λ…μκµ­κ°€μ½”λ“1" FROM "US_REL_PSN" WHERE "κµ¬λ¶„" = 'λ°λ…μ' AND "μΌλ ¨λ²νΈ" = 1 ) F ON Z.λ¬Έν—λ²νΈ = F.λ¬Έν—λ²νΈ
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, ipcμ½”λ“ FROM "US_IPC" WHERE μΌλ ¨λ²νΈ = 1 ) H ON Z.λ¬Έν—λ²νΈ = H.λ¬Έν—λ²νΈ 
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, μ°μ„ κ¶μ£Όμ¥μ¶μ›λ²νΈ AS "μ°λ²1" FROM "US_PRIR" WHERE "μΌλ ¨λ²νΈ" = 1 ) K ON Z.λ¬Έν—λ²νΈ = K.λ¬Έν—λ²νΈ
            LEFT JOIN ( SELECT λ¬Έν—λ²νΈ, μ°μ„ κ¶μ£Όμ¥μ¶μ›λ²νΈ AS "μ°λ²2" FROM "US_PRIR" WHERE "μΌλ ¨λ²νΈ" = 2 ) L ON Z.λ¬Έν—λ²νΈ = L.λ¬Έν—λ²νΈ                  
        """
